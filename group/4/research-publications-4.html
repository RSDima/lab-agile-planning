<!DOCTYPE html>
<html lang="en" dir="ltr" prefix="content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# ">
  <head>
    <meta charset="utf-8">
<noscript><style>form.antibot * :not(.antibot-message) { display: none !important; }</style>
</noscript><meta name="Generator" content="Drupal 9 (https://www.drupal.org)">
<meta name="MobileOptimized" content="width">
<meta name="HandheldFriendly" content="true">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/muli_regular/font-1.css" media="all">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/muli_semibold/font-1.css" media="all">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/open_sans_regular/font-1.css" media="all">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/open_sans_bold/font-1.css" media="all">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/muli_light/font-1.css" media="all">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/open_sans_semibold/font-1.css" media="all">
<link rel="stylesheet" href="../../sites/default/files/fontyourface/local_fonts/open_sans_light/font-1.css" media="all">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<link rel="icon" href="../../themes/custom/cair_sass/favicon-1.ico" type="image/vnd.microsoft.icon">
<script>window.a2a_config=window.a2a_config||{};a2a_config.callbacks=[];a2a_config.overlays=[];a2a_config.templates={};</script>

    <title>CAIR Deep Learning Research Publications | CAIR</title>
    <link rel="stylesheet" media="all" href="../../core/modules/system/css/components/ajax-progress.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/align.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/autocomplete-loading.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/fieldgroup.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/container-inline.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/clearfix.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/details.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/hidden.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/item-list.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/js.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/nowrap.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/position-container.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/progress.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/reset-appearance.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/resize.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/sticky-header.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/system-status-counter-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/system-status-report-counters-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/system-status-report-general-info-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/tabledrag.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/tablesort.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/system/css/components/tree-child.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../core/modules/views/css/views.module-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../modules/contrib/addtoany/css/addtoany-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../modules/custom/particlesjs/particlesjs_cair/css/particlesjs_cair-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../themes/custom/cair_sass/css/style-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../themes/custom/cair_sass/css/custom-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../themes/contrib/bootstrap_barrio/css/components/breadcrumb-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../themes/contrib/bootstrap_barrio/css/components/form-1.css?s9x51z">
<link rel="stylesheet" media="all" href="../../themes/contrib/bootstrap_barrio/css/components/tabs-1.css?s9x51z">

    
  </head>
  <body class="fontyourface layout-one-sidebar layout-sidebar-first page-view-group-nodes path-group">
    <a href="#main-content" class="visually-hidden focusable skip-link">
      Skip to main content
    </a>
    
      <div class="dialog-off-canvas-main-canvas" data-off-canvas-main-canvas="">
    <div id="page-wrapper">
  <div id="page">
    <header id="header" class="header" role="banner" aria-label="Site header">
                      <nav class="navbar navbar-light bg-light navbar-expand-lg" id="navbar-main">
                    <div class="container">
                              <a href="../../index-1.htm" title="Home" rel="home" class="navbar-brand">
            <span class="ml-2 d-none d-md-inline">CAIR</span>
    </a>
    

                          <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#CollapsingNavbar" aria-controls="CollapsingNavbar" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
              <div class="collapse navbar-collapse" id="CollapsingNavbar">
                  <nav role="navigation" aria-labelledby="block-cair-sass-main-menu-menu" id="block-cair-sass-main-menu" class="block block-menu navigation menu--main">
            
  <h2 class="sr-only" id="block-cair-sass-main-menu-menu">Main navigation</h2>
  

        
              <ul block="block-cair-sass-main-menu" class="clearfix nav navbar-nav">
                    <li class="nav-item">
                          <a href="../../group-1.html" class="nav-link nav-link--group" data-drupal-link-system-path="node/18">Research Groups</a>
              </li>
                <li class="nav-item">
                          <a href="../../people-9.html" class="nav-link nav-link--people" data-drupal-link-system-path="node/23">People</a>
              </li>
                <li class="nav-item">
                          <a href="../../research-publications-18.html" class="nav-link nav-link--research-publications" data-drupal-link-system-path="node/22">Research Publications</a>
              </li>
                <li class="nav-item">
                          <a href="../../about-1.html" class="nav-link nav-link--about" data-drupal-link-system-path="node/4">About</a>
              </li>
                <li class="nav-item">
                          <a href="../../contact-1.html" class="nav-link nav-link--contact" data-drupal-link-system-path="webform/contact">Contact</a>
              </li>
        </ul>
  


  </nav>
<nav role="navigation" aria-labelledby="block-searchmenu-menu" id="block-searchmenu" class="block block-menu navigation menu--search-menu">
            
  <h2 class="sr-only" id="block-searchmenu-menu">Search menu</h2>
  

        
              <ul block="block-searchmenu" class="clearfix nav">
                    <li class="nav-item">
                
        <a href="../../search-1.html" class="nav-item nav-link">
            <span>Search</span>
        </a>

              </li>
        </ul>
  


  </nav>


                	          </div>
            
                          <div class="search-expandable px-3 z-10 invisible">
                <div class="d-flex align-items-center h-100 justify-content-center mw-760 mx-auto">  <div class="views-exposed-form block block-views block-views-exposed-filter-blocksearch-api-database-search-page-1" data-drupal-selector="views-exposed-form-search-api-database-search-page-1" id="block-exposedformsearch-api-database-searchpage-1">
  
    
      <div class="content">
      
      <div class="form-row">
        
<form action="/search" method="get" id="views-exposed-form-search-api-database-search-page-1" accept-charset="UTF-8">
  <div class="form-row">
  



  <fieldset class="js-form-item js-form-type-textfield form-type-textfield js-form-item-search-api-fulltext form-item-search-api-fulltext form-no-label form-group">
                    <input placeholder="Search for content or users" data-drupal-selector="edit-search-api-fulltext" type="text" id="edit-search-api-fulltext" name="search_api_fulltext" value="" size="30" maxlength="128" class="form-text form-control">

                      </fieldset>
<div data-drupal-selector="edit-actions" class="form-actions js-form-wrapper form-group col-auto" id="edit-actions"><input data-drupal-selector="edit-submit-search-api-database-search" type="submit" id="edit-submit-search-api-database-search" value="Apply" class="button js-form-submit form-submit btn btn-primary form-control">
</div>

</div>

</form>

        <div class="col">
          <button type="reset" class="btn btn-link search-reset">Close</button>
        </div>
      </div>

    </div>
  </div>

</div>
              </div>
                        
                                </div>
                  </nav>
          </header>
                <div class="breadcrumb-wrapper position-relative d-flex align-items-center fade-in">
      <div class="container">  <div id="block-cair-sass-breadcrumbs" class="block block-system block-system-breadcrumb-block">
  
    
      <div class="content">
      

  <nav role="navigation" aria-label="breadcrumb">
    <ol class="breadcrumb">
                  <li class="breadcrumb-item">
          <a href="../../index-1.htm">Home</a>
        </li>
                        <li class="breadcrumb-item">
          <a href="../../group-1.html">Research Groups</a>
        </li>
                        <li class="breadcrumb-item">
          <a href="../4-1.html">CAIR Deep Learning</a>
        </li>
              </ol>
  </nav>

    </div>
  </div>

</div>
        <section class="row region region-breadcrumb-bg">
    <div id="block-particlesjsexampleblock" class="block block-particlesjs-cair block-particlesjsexample">
  
    
       <div id="particles-js" class="h-100"></div>
  </div>

  </section>

    </div>
          <div class="bg-grey py-3 mb-4">
        <div class="container d-flex align-items-center page-title">
            <div class="views-element-container thumb-lg mr-4 block block-views block-views-blockuniversity-logo-block-1" id="block-views-block-university-logo-block-1">
  
    
      <div class="content">
      <div class="col-auto"><div class="view view-university-logo view-id-university_logo view-display-id-block_1 js-view-dom-id-058db0aeaef3c3dfa8644401d739617d3add765c551fbcc3d73500e1e8ca1f83">
  
    
      
      <div class="view-content row">
          <div class="views-row">
    <div class="views-field views-field-field-image"><div class="field-content">  <img src="../../sites/default/files/styles/medium/public/2019-07/nwu-logo-purple-1.png?itok=wb1cE8Jy" width="220" height="152" alt="North West University" loading="lazy" typeof="foaf:Image" class="image-style-medium">


</div></div>
  </div>

    </div>
  
          </div>
</div>

    </div>
  </div>
<div id="block-page-title-block" class="block block-core block-page-title-block">
  
    
      <div class="content">
      
  <h1 class="title"><em class="placeholder">CAIR Deep Learning</em> Research Publications</h1>


    </div>
  </div>


        </div>
      </div>
        <div id="main-wrapper" class="layout-main-wrapper clearfix pt-3">
              <div id="main" class="container">
          <div class="row row-offcanvas row-offcanvas-left clearfix">
              <main class="main-content col" id="content" role="main">
                <section class="section">
                  <a id="main-content" tabindex="-1"></a>
                    <div data-drupal-messages-fallback="" class="hidden"></div>
      <nav class="tabs" role="navigation" aria-label="Tabs">
      
  <h2 class="visually-hidden">Primary tabs</h2>
  <ul class="nav nav-tabs primary"><li class="nav-item"><a href="../4-1.html" class="nav-link nav-link--group-4">View</a></li>
<li class="nav-item"><a href="members-1.html" class="nav-link nav-link--group-4-members">People</a></li>
<li class="active nav-item"><a href="research-publications-4.html" class="nav-link active nav-link--group-4-research-publications">Research Publications</a></li>
<li class="nav-item"><a href="news-3.html" class="nav-link nav-link--group-4-news">News</a></li>
<li class="nav-item"><a href="events-3.html" class="nav-link nav-link--group-4-events">Events</a></li>
</ul>

    </nav>
  <div id="block-cair-sass-content" class="block block-system block-system-main-block">
  
    
      <div class="content">
      <div class="views-element-container col-auto"><div class="js-view-dom-id-5740157e3f440b772f0b20d32953e7f2b2087be6d60cbd7e18e51c71ee595508 listing-bordered">
  
  
  

  
  
  

  <div>
  <h3 class="mb-3">2022</h3>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-492">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Heymans W, Davel MH, Van Heerden CJ. Efficient acoustic feature transformation in mismatched environments using a Guided-GAN. <i>Speech Communication</i>. 2022;143. doi:https://doi.org/10.1016/j.specom.2022.07.002.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-492" role="button" aria-expanded="false" aria-controls="collapseAbstract-492">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-492" role="button" aria-expanded="false" aria-controls="collapseBibtext-492">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-492-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                 
    </div>

    <div class="collapse" data-parent="#row-492" id="collapsePdf-492">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-492" id="collapseAbstract-492">
        <div class="p-3 border-left-grey mt-2">
            <p>We propose a new framework to improve automatic speech recognition (ASR) systems in resource-scarce environments using a generative adversarial network (GAN) operating on acoustic input features. The GAN is used to enhance the features of mismatched data prior to decoding, or can optionally be used to fine-tune the acoustic model. We achieve improvements that are comparable to multi-style training (MTR), but at a lower computational cost. With less than one hour of data, an ASR system trained on good quality data, and evaluated on mismatched audio is improved by between 11.5% and 19.7% relative word error rate (WER). Experiments demonstrate that the framework can be very useful in under-resourced environments where training data and computational resources are limited. The GAN does not require parallel training data, because it utilises a baseline acoustic model to provide an additional loss term that guides the generator to create acoustic features that are better classified by the baseline.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-492" id="collapseBibtext-492">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;492,
&nbsp;&nbsp;author = &#123;Walter Heymans and Marelie Davel and Charl Van Heerden&#125;,
&nbsp;&nbsp;title = &#123;Efficient acoustic feature transformation in mismatched environments using a Guided-GAN&#125;,
&nbsp;&nbsp;abstract = &#123;We propose a new framework to improve automatic speech recognition (ASR) systems in resource-scarce environments using a generative adversarial network (GAN) operating on acoustic input features. The GAN is used to enhance the features of mismatched data prior to decoding, or can optionally be used to fine-tune the acoustic model. We achieve improvements that are comparable to multi-style training (MTR), but at a lower computational cost. With less than one hour of data, an ASR system trained on good quality data, and evaluated on mismatched audio is improved by between 11.5% and 19.7% relative word error rate (WER). Experiments demonstrate that the framework can be very useful in under-resourced environments where training data and computational resources are limited. The GAN does not require parallel training data, because it utilises a baseline acoustic model to provide an additional loss term that guides the generator to create acoustic features that are better classified by the baseline.&#125;,
&nbsp;&nbsp;year = &#123;2022&#125;,
&nbsp;&nbsp;journal = &#123;Speech Communication&#125;,
&nbsp;&nbsp;volume = &#123;143&#125;,
&nbsp;&nbsp;pages = &#123;10 - 20&#125;,
&nbsp;&nbsp;month = &#123;09/2022&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1016/j.specom.2022.07.002&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">

<div class="mb-20" id="row-491">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Oosthuizen AJ, Davel MH, Helberg A. Multi-Layer Perceptron for Channel State Information Estimation: Design Considerations. In: <i>Southern Africa Telecommunication Networks and Applications Conference (SATNAC)</i>. Fancourt, George; 2022.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-491" role="button" aria-expanded="false" aria-controls="collapseAbstract-491">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-491" role="button" aria-expanded="false" aria-controls="collapseBibtext-491">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-491-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-491" role="button" aria-expanded="false" aria-controls="collapsePdf-491">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-491" id="collapsePdf-491">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2022-09/SATNAC2022%20Multi-Layer%20Perceptron%20for%20Channel%20State%20Information%20Estimation%20Design%20Considerations-1.pdf" type="application/pdf">SATNAC2022 Multi-Layer Perceptron for Channel State Information Estimation Design Considerations.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-491" id="collapseAbstract-491">
        <div class="p-3 border-left-grey mt-2">
            <p>The accurate estimation of channel state information (CSI) is an important aspect of wireless communications. In this paper, a multi-layer perceptron (MLP) is developed as a CSI estimator in long-term evolution (LTE) transmission conditions. The representation of the CSI data is investigated in conjunction with batch normalisation and the representational ability of MLPs. It is found that discontinuities in the representational feature space can cripple an MLP’s ability to accurately predict CSI when noise is present. Different ways in which to mitigate this effect are analysed and a solution developed, initially in the context of channels that are only affected by additive white
Guassian noise. The developed architecture is then applied to more complex channels with various delay profiles and Doppler spread. The performance of the proposed MLP is shown to be comparable with LTE minimum mean squared error (MMSE), and to outperform least square (LS) estimation over a range of channel conditions.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-491" id="collapseBibtext-491">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;491,
&nbsp;&nbsp;author = &#123;Andrew Oosthuizen and Marelie Davel and Albert Helberg&#125;,
&nbsp;&nbsp;title = &#123;Multi-Layer Perceptron for Channel State Information Estimation: Design Considerations&#125;,
&nbsp;&nbsp;abstract = &#123;The accurate estimation of channel state information (CSI) is an important aspect of wireless communications. In this paper, a multi-layer perceptron (MLP) is developed as a CSI estimator in long-term evolution (LTE) transmission conditions. The representation of the CSI data is investigated in conjunction with batch normalisation and the representational ability of MLPs. It is found that discontinuities in the representational feature space can cripple an MLP’s ability to accurately predict CSI when noise is present. Different ways in which to mitigate this effect are analysed and a solution developed, initially in the context of channels that are only affected by additive white
Guassian noise. The developed architecture is then applied to more complex channels with various delay profiles and Doppler spread. The performance of the proposed MLP is shown to be comparable with LTE minimum mean squared error (MMSE), and to outperform least square (LS) estimation over a range of channel conditions.&#125;,
&nbsp;&nbsp;year = &#123;2022&#125;,
&nbsp;&nbsp;journal = &#123;Southern Africa Telecommunication Networks and Applications Conference (SATNAC)&#125;,
&nbsp;&nbsp;pages = &#123;94 - 99&#125;,
&nbsp;&nbsp;month = &#123;08/2022&#125;,
&nbsp;&nbsp;address = &#123;Fancourt, George&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-483">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Modipa T, Davel MH. Two Sepedi‑English code‑switched speech corpora. <i>Language Resources and Evaluation</i>. 2022;56. doi:https://doi.org/10.1007/s10579-022-09592-6 (Read here: https://rdcu.be/cO6lD).</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-483" role="button" aria-expanded="false" aria-controls="collapseAbstract-483">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-483" role="button" aria-expanded="false" aria-controls="collapseBibtext-483">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-483-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                 
    </div>

    <div class="collapse" data-parent="#row-483" id="collapsePdf-483">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-483" id="collapseAbstract-483">
        <div class="p-3 border-left-grey mt-2">
            <p>We report on the development of two reference corpora for the analysis of SepediEnglish code-switched speech in the context of automatic speech recognition. For the first corpus, possible English events were obtained from an existing corpus of transcribed Sepedi-English speech. The second corpus is based on the analysis of radio broadcasts: actual instances of code switching were transcribed and reproduced by a number of native Sepedi speakers. We describe the process to develop and verify both corpora and perform an initial analysis of the newly produced data sets. We find that, in naturally occurring speech, the frequency of code switching is unexpectedly high for this language pair, and that the continuum of code switching (from unmodified embedded words to loanwords absorbed into the matrix language) makes this a particularly challenging task for speech recognition systems.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-483" id="collapseBibtext-483">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;483,
&nbsp;&nbsp;author = &#123;Thipe Modipa and Marelie Davel&#125;,
&nbsp;&nbsp;title = &#123;Two Sepedi‑English code‑switched speech corpora&#125;,
&nbsp;&nbsp;abstract = &#123;We report on the development of two reference corpora for the analysis of SepediEnglish code-switched speech in the context of automatic speech recognition. For the first corpus, possible English events were obtained from an existing corpus of transcribed Sepedi-English speech. The second corpus is based on the analysis of radio broadcasts: actual instances of code switching were transcribed and reproduced by a number of native Sepedi speakers. We describe the process to develop and verify both corpora and perform an initial analysis of the newly produced data sets. We find that, in naturally occurring speech, the frequency of code switching is unexpectedly high for this language pair, and that the continuum of code switching (from unmodified embedded words to loanwords absorbed into the matrix language) makes this a particularly challenging task for speech recognition systems.&#125;,
&nbsp;&nbsp;year = &#123;2022&#125;,
&nbsp;&nbsp;journal = &#123;Language Resources and Evaluation&#125;,
&nbsp;&nbsp;volume = &#123;56&#125;,
&nbsp;&nbsp;pages = &#123;https://rdcu.be/cO6lD)&#125;,
&nbsp;&nbsp;publisher = &#123;Springer&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;url = &#123;https://rdcu.be/cO6lD&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1007/s10579-022-09592-6 (Read here: https://rdcu.be/cO6lD)&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-480">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Heymans W, Davel MH, Van Heerden CJ. Multi-style Training for South African Call Centre Audio. <i>Communications in Computer and Information Science</i>. 2022;1551. doi:https://doi.org/10.1007/978-3-030-95070-5_8.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-480" role="button" aria-expanded="false" aria-controls="collapseAbstract-480">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-480" role="button" aria-expanded="false" aria-controls="collapseBibtext-480">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-480-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-480" role="button" aria-expanded="false" aria-controls="collapsePdf-480">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-480" id="collapsePdf-480">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2022-06/Multi-style%20Training%20for%20South%20African%20Call%20Centre%20Audio-1.pdf" type="application/pdf">Multi-style Training for South African Call Centre Audio.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-480" id="collapseAbstract-480">
        <div class="p-3 border-left-grey mt-2">
            <p>Mismatched data is a challenging problem for automatic speech recognition (ASR) systems. One of the most common techniques used to address mismatched data is multi-style training (MTR), a form of data augmentation that attempts to transform the training data to be more representative of the testing data; and to learn robust representations applicable to different conditions. This task can be very challenging if the test conditions are unknown. We explore the impact of different MTR styles on system performance when testing conditions are different from training conditions in the context of deep neural network hidden Markov model (DNN-HMM) ASR systems. A controlled environment is created using the LibriSpeech corpus, where we isolate the effect of different MTR styles on final system performance. We evaluate our findings on a South African call centre dataset that contains noisy, WAV49-encoded audio.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-480" id="collapseBibtext-480">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;480,
&nbsp;&nbsp;author = &#123;Walter Heymans and Marelie Davel and Charl Van Heerden&#125;,
&nbsp;&nbsp;title = &#123;Multi-style Training for South African Call Centre Audio&#125;,
&nbsp;&nbsp;abstract = &#123;Mismatched data is a challenging problem for automatic speech recognition (ASR) systems. One of the most common techniques used to address mismatched data is multi-style training (MTR), a form of data augmentation that attempts to transform the training data to be more representative of the testing data; and to learn robust representations applicable to different conditions. This task can be very challenging if the test conditions are unknown. We explore the impact of different MTR styles on system performance when testing conditions are different from training conditions in the context of deep neural network hidden Markov model (DNN-HMM) ASR systems. A controlled environment is created using the LibriSpeech corpus, where we isolate the effect of different MTR styles on final system performance. We evaluate our findings on a South African call centre dataset that contains noisy, WAV49-encoded audio.&#125;,
&nbsp;&nbsp;year = &#123;2022&#125;,
&nbsp;&nbsp;journal = &#123;Communications in Computer and Information Science&#125;,
&nbsp;&nbsp;volume = &#123;1551&#125;,
&nbsp;&nbsp;pages = &#123;111 - 124&#125;,
&nbsp;&nbsp;publisher = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1007/978-3-030-95070-5_8&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-479">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Mouton C, Davel MH. Exploring layerwise decision making in DNNs. <i>Communications in Computer and Information Science</i>. 2022;1551. doi:https://doi.org/10.1007/978-3-030-95070-5_10.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-479" role="button" aria-expanded="false" aria-controls="collapseAbstract-479">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-479" role="button" aria-expanded="false" aria-controls="collapseBibtext-479">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-479-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-479" role="button" aria-expanded="false" aria-controls="collapsePdf-479">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-479" id="collapsePdf-479">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2022-06/Exploring%20layerwise%20decision%20making%20in%20DNNs-1.pdf" type="application/pdf">Exploring layerwise decision making in DNNs.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-479" id="collapseAbstract-479">
        <div class="p-3 border-left-grey mt-2">
            <p>While deep neural networks (DNNs) have become a standard architecture for many machine learning tasks, their internal decision-making process and general interpretability is still poorly understood. Conversely, common decision trees are easily interpretable and theoretically well understood. We show that by encoding the discrete sample activation values of nodes as a binary representation, we are able to extract a decision tree explaining the classification procedure of each layer in a ReLU-activated multilayer perceptron (MLP). We then combine these decision trees with existing feature attribution techniques in order to produce an interpretation of each layer of a model. Finally, we provide an analysis of the generated interpretations, the behaviour of the binary encodings and how these relate to sample groupings created during the training process of the neural network.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-479" id="collapseBibtext-479">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;479,
&nbsp;&nbsp;author = &#123;Coenraad Mouton and Marelie Davel&#125;,
&nbsp;&nbsp;title = &#123;Exploring layerwise decision making in DNNs&#125;,
&nbsp;&nbsp;abstract = &#123;While deep neural networks (DNNs) have become a standard architecture for many machine learning tasks, their internal decision-making process and general interpretability is still poorly understood. Conversely, common decision trees are easily interpretable and theoretically well understood. We show that by encoding the discrete sample activation values of nodes as a binary representation, we are able to extract a decision tree explaining the classification procedure of each layer in a ReLU-activated multilayer perceptron (MLP). We then combine these decision trees with existing feature attribution techniques in order to produce an interpretation of each layer of a model. Finally, we provide an analysis of the generated interpretations, the behaviour of the binary encodings and how these relate to sample groupings created during the training process of the neural network.&#125;,
&nbsp;&nbsp;year = &#123;2022&#125;,
&nbsp;&nbsp;journal = &#123;Communications in Computer and Information Science&#125;,
&nbsp;&nbsp;volume = &#123;1551&#125;,
&nbsp;&nbsp;pages = &#123;140 - 155&#125;,
&nbsp;&nbsp;publisher = &#123;Artificial Intelligence Research (SACAIR 2021)&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1007/978-3-030-95070-5_10&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
</div>
<div>
  <h3 class="mb-3">2021</h3>
    <div class="w-100 views-row">

<div class="mb-20" id="row-482">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Van Wyk L, Davel MH, Van Heerden CJ. Unsupervised fine-tuning of speaker diarisation pipelines using silhouette coefficients. In: <i>Southern African Conference for Artificial Intelligence Research</i>. South Africa; 2021. https://2021.sacair.org.za/proceedings/.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-482" role="button" aria-expanded="false" aria-controls="collapseAbstract-482">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-482" role="button" aria-expanded="false" aria-controls="collapseBibtext-482">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-482-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-482" role="button" aria-expanded="false" aria-controls="collapsePdf-482">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-482" id="collapsePdf-482">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2022-06/Unsupervised%20fine-tuning%20of%20speaker%20diarisation%20pipelines%20using%20silhouette%20coefficients-1.pdf" type="application/pdf">Unsupervised fine-tuning of speaker diarisation pipelines using silhouette coefficients.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-482" id="collapseAbstract-482">
        <div class="p-3 border-left-grey mt-2">
            <p>We investigate the use of silhouette coefficients in cluster analysis for speaker diarisation, with the dual purpose of unsupervised fine-tuning during domain adaptation and determining the number of speakers in an audio file. Our main contribution is to demonstrate the use of silhouette coefficients to perform per-file domain adaptation, which we show to deliver an improvement over per-corpus domain adaptation. Secondly, we show that this method of silhouette-based cluster analysis can be used to accurately determine more than one hyperparameter at the same time. Finally, we propose a novel method for calculating the silhouette coefficient of clusters using a PLDA score matrix as input.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-482" id="collapseBibtext-482">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;482,
&nbsp;&nbsp;author = &#123;Lucas Van Wyk and Marelie Davel and Charl Van Heerden&#125;,
&nbsp;&nbsp;title = &#123;Unsupervised fine-tuning of speaker diarisation pipelines using silhouette coefficients&#125;,
&nbsp;&nbsp;abstract = &#123;We investigate the use of silhouette coefficients in cluster analysis for speaker diarisation, with the dual purpose of unsupervised fine-tuning during domain adaptation and determining the number of speakers in an audio file. Our main contribution is to demonstrate the use of silhouette coefficients to perform per-file domain adaptation, which we show to deliver an improvement over per-corpus domain adaptation. Secondly, we show that this method of silhouette-based cluster analysis can be used to accurately determine more than one hyperparameter at the same time. Finally, we propose a novel method for calculating the silhouette coefficient of clusters using a PLDA score matrix as input.&#125;,
&nbsp;&nbsp;year = &#123;2021&#125;,
&nbsp;&nbsp;journal = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;pages = &#123;202 - 216&#125;,
&nbsp;&nbsp;month = &#123;06/12/2021 - 10/12/2021&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-0-620-94410-6&#125;,
&nbsp;&nbsp;url = &#123;https://2021.sacair.org.za/proceedings/&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">

<div class="mb-20" id="row-481">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Oosthuizen AJ, Davel MH, Helberg A. Exploring CNN-based automatic modulation classification using small modulation sets. In: <i>Southern Africa Telecommunication Networks and Applications Conference</i>. South Africa; 2021. https://www.satnac.org.za/proceedings.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-481" role="button" aria-expanded="false" aria-controls="collapseAbstract-481">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-481" role="button" aria-expanded="false" aria-controls="collapseBibtext-481">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-481-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-481" role="button" aria-expanded="false" aria-controls="collapsePdf-481">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-481" id="collapsePdf-481">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2022-06/Exploring%20CNN-based%20automatic%20modulation%20classification%20using%20small%20modulation%20sets-1.pdf" type="application/pdf">Exploring CNN-based automatic modulation classification using small modulation sets.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-481" id="collapseAbstract-481">
        <div class="p-3 border-left-grey mt-2">
            <p>We investigate the effect of a reduced modulation scheme pool on a CNN-based automatic modulation classifier. Similar classifiers in literature are typically used to classify sets of five or more different modulation types [1] [2], whereas our
analysis is of a CNN classifier that classifies between two modulation types, 16-QAM and 8-PSK, only. While implementing the network, we observe that the network’s classification accuracy improves for lower SNR instead of reducing as expected. This analysis exposes characteristics of such classifiers that can be used to improve CNN classifiers on larger sets of modulation types. We show that presenting the SNR data as an extra data point to the network can significantly increase classification accuracy.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-481" id="collapseBibtext-481">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;481,
&nbsp;&nbsp;author = &#123;Andrew Oosthuizen and Marelie Davel and Albert Helberg&#125;,
&nbsp;&nbsp;title = &#123;Exploring CNN-based automatic modulation classification using small modulation sets&#125;,
&nbsp;&nbsp;abstract = &#123;We investigate the effect of a reduced modulation scheme pool on a CNN-based automatic modulation classifier. Similar classifiers in literature are typically used to classify sets of five or more different modulation types [1] [2], whereas our
analysis is of a CNN classifier that classifies between two modulation types, 16-QAM and 8-PSK, only. While implementing the network, we observe that the network’s classification accuracy improves for lower SNR instead of reducing as expected. This analysis exposes characteristics of such classifiers that can be used to improve CNN classifiers on larger sets of modulation types. We show that presenting the SNR data as an extra data point to the network can significantly increase classification accuracy.&#125;,
&nbsp;&nbsp;year = &#123;2021&#125;,
&nbsp;&nbsp;journal = &#123;Southern Africa Telecommunication Networks and Applications Conference&#125;,
&nbsp;&nbsp;pages = &#123;20 - 24&#125;,
&nbsp;&nbsp;month = &#123;21/11/2021 - 23/11/2021&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;url = &#123;https://www.satnac.org.za/proceedings&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
</div>
<div>
  <h3 class="mb-3">2020</h3>
    <div class="w-100 views-row">

<div class="mb-20" id="row-404">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Lamprecht DB, Barnard E. Using a meta-model to compensate for training-evaluation mismatches. In: <i>Southern African Conference for Artificial Intelligence Research</i>. South Africa; 2020. https://sacair.org.za/proceedings/.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-404" role="button" aria-expanded="false" aria-controls="collapseAbstract-404">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-404" role="button" aria-expanded="false" aria-controls="collapseBibtext-404">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-404-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-404" role="button" aria-expanded="false" aria-controls="collapsePdf-404">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-404" id="collapsePdf-404">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/Lamprecht-2020-using-meta-model_0-1.pdf" type="application/pdf">Lamprecht-2020-using-meta-model_0.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-404" id="collapseAbstract-404">
        <div class="p-3 border-left-grey mt-2">
            <p>One of the fundamental assumptions of machine learning is that learnt models are applied to data that is identically distributed to the training data. This assumption is often not realistic: for example, data collected from a single source at different times may not be distributed identically, due to sampling bias or changes in the environment. We propose a new architecture called a meta-model which predicts performance for unseen models. This approach is applicable when several ‘proxy’ datasets are available to train a model to be deployed on a ‘target’ test set; the architecture is used to identify which regression algorithms should be used as well as which datasets are most useful to train for a given target dataset. Finally, we demonstrate the strengths and weaknesses of the proposed meta-model by making use of artificially generated datasets using a variation of the Friedman method 3 used to generate artificial regression datasets, and discuss real-world applications of our approach.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-404" id="collapseBibtext-404">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;404,
&nbsp;&nbsp;author = &#123;Dylan Lamprecht and Etienne Barnard&#125;,
&nbsp;&nbsp;title = &#123;Using a meta-model to compensate for training-evaluation mismatches&#125;,
&nbsp;&nbsp;abstract = &#123;One of the fundamental assumptions of machine learning is that learnt models are applied to data that is identically distributed to the training data. This assumption is often not realistic: for example, data collected from a single source at different times may not be distributed identically, due to sampling bias or changes in the environment. We propose a new architecture called a meta-model which predicts performance for unseen models. This approach is applicable when several ‘proxy’ datasets are available to train a model to be deployed on a ‘target’ test set; the architecture is used to identify which regression algorithms should be used as well as which datasets are most useful to train for a given target dataset. Finally, we demonstrate the strengths and weaknesses of the proposed meta-model by making use of artificially generated datasets using a variation of the Friedman method 3 used to generate artificial regression datasets, and discuss real-world applications of our approach.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;pages = &#123;321-334&#125;,
&nbsp;&nbsp;month = &#123;22/02/2021 - 26/02/2021&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-0-620-89373-2&#125;,
&nbsp;&nbsp;url = &#123;https://sacair.org.za/proceedings/&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">

<div class="mb-20" id="row-403">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Heyns N, Barnard E. Optimising word embeddings for recognised multilingual speech. In: <i>Southern African Conference for Artificial Intelligence Research</i>. South Africa; 2020. https://sacair.org.za/proceedings/.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-403" role="button" aria-expanded="false" aria-controls="collapseAbstract-403">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-403" role="button" aria-expanded="false" aria-controls="collapseBibtext-403">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-403-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-403" role="button" aria-expanded="false" aria-controls="collapsePdf-403">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-403" id="collapsePdf-403">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/heyns-2020-optimising-word-embeddings_0-1.pdf" type="application/pdf">heyns-2020-optimising-word-embeddings_0.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-403" id="collapseAbstract-403">
        <div class="p-3 border-left-grey mt-2">
            <p>Word embeddings are widely used in natural language processing (NLP) tasks. Most work on word embeddings focuses on monolingual languages with large available datasets. For embeddings to be useful in a multilingual environment, as in South Africa, the training techniques have to be adjusted to cater for a) multiple languages, b) smaller datasets and c) the occurrence of code-switching. One of the biggest roadblocks is to obtain datasets that include examples of natural code-switching, since code switching is generally avoided in written material. A solution to this problem is to use speech recognised data. Embedding packages like Word2Vec and GloVe have default hyper-parameter settings that are usually optimised for training on large datasets and evaluation on analogy tasks. When using embeddings for problems such as text classification in our multilingual environment, the hyper-parameters have to be optimised for the specific data and task. We investigate the importance of optimising relevant hyper-parameters for training word embeddings with speech recognised data, where code-switching occurs, and evaluate against the real-world problem of classifying radio and television recordings with code switching. We compare these models with a bag of words baseline model as well as a pre-trained GloVe model.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-403" id="collapseBibtext-403">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;403,
&nbsp;&nbsp;author = &#123;Nuette Heyns and Etienne Barnard&#125;,
&nbsp;&nbsp;title = &#123;Optimising word embeddings for recognised multilingual speech&#125;,
&nbsp;&nbsp;abstract = &#123;Word embeddings are widely used in natural language processing (NLP) tasks. Most work on word embeddings focuses on monolingual languages with large available datasets. For embeddings to be useful in a multilingual environment, as in South Africa, the training techniques have to be adjusted to cater for a) multiple languages, b) smaller datasets and c) the occurrence of code-switching. One of the biggest roadblocks is to obtain datasets that include examples of natural code-switching, since code switching is generally avoided in written material. A solution to this problem is to use speech recognised data. Embedding packages like Word2Vec and GloVe have default hyper-parameter settings that are usually optimised for training on large datasets and evaluation on analogy tasks. When using embeddings for problems such as text classification in our multilingual environment, the hyper-parameters have to be optimised for the specific data and task. We investigate the importance of optimising relevant hyper-parameters for training word embeddings with speech recognised data, where code-switching occurs, and evaluate against the real-world problem of classifying radio and television recordings with code switching. We compare these models with a bag of words baseline model as well as a pre-trained GloVe model.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;pages = &#123;102-116&#125;,
&nbsp;&nbsp;month = &#123;22/02/2021 - 26/02/2021&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-0-620-89373-2&#125;,
&nbsp;&nbsp;url = &#123;https://sacair.org.za/proceedings/&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">

<div class="mb-20" id="row-402">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Haasbroek DG, Davel MH. Exploring neural network training dynamics through binary node activations. In: <i>Southern African Conference for Artificial Intelligence Research</i>. South Africa; 2020. https://sacair.org.za/proceedings/.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-402" role="button" aria-expanded="false" aria-controls="collapseAbstract-402">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-402" role="button" aria-expanded="false" aria-controls="collapseBibtext-402">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-402-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-402" role="button" aria-expanded="false" aria-controls="collapsePdf-402">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-402" id="collapsePdf-402">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/Haasbroek-2020-exploring-nn-training_0-1.pdf" type="application/pdf">Haasbroek-2020-exploring-nn-training_0.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-402" id="collapseAbstract-402">
        <div class="p-3 border-left-grey mt-2">
            <p>Each node in a neural network is trained to activate for a specific region in the input domain. Any training samples that fall within this domain are therefore implicitly clustered together. Recent work has highlighted the importance of these clusters during the training process but has not yet investigated their evolution during training. Towards this goal, we train several ReLU-activated MLPs on a simple classification task (MNIST) and show that a consistent training process emerges: (1) sample clusters initially increase in size and then decrease as training progresses, (2) the size of sample clusters in the first layer decreases more rapidly than in deeper layers, (3) binary node activations, especially of nodes in deeper layers, become more sensitive to class membership as training progresses, (4) individual nodes remain poor predictors of class membership, even if accurate when applied as a group. We report on the detail of these findings and interpret them from the perspective of a high-dimensional clustering process.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-402" id="collapseBibtext-402">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;402,
&nbsp;&nbsp;author = &#123;Daniël Haasbroek and Marelie Davel&#125;,
&nbsp;&nbsp;title = &#123;Exploring neural network training dynamics through binary node activations&#125;,
&nbsp;&nbsp;abstract = &#123;Each node in a neural network is trained to activate for a specific region in the input domain. Any training samples that fall within this domain are therefore implicitly clustered together. Recent work has highlighted the importance of these clusters during the training process but has not yet investigated their evolution during training. Towards this goal, we train several ReLU-activated MLPs on a simple classification task (MNIST) and show that a consistent training process emerges: (1) sample clusters initially increase in size and then decrease as training progresses, (2) the size of sample clusters in the first layer decreases more rapidly than in deeper layers, (3) binary node activations, especially of nodes in deeper layers, become more sensitive to class membership as training progresses, (4) individual nodes remain poor predictors of class membership, even if accurate when applied as a group. We report on the detail of these findings and interpret them from the perspective of a high-dimensional clustering process.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;pages = &#123;304-320&#125;,
&nbsp;&nbsp;month = &#123;22/02/2021 - 26/02/2021&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-0-620-89373-2&#125;,
&nbsp;&nbsp;url = &#123;https://sacair.org.za/proceedings/&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-484">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Venter AE, Theunissen MW, Davel MH. Pre-interpolation loss behaviour in neural networks. <i>Communications in Computer and Information Science</i>. 2020;1342. doi:https://doi.org/10.1007/978-3-030-66151-9_19.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-484" role="button" aria-expanded="false" aria-controls="collapseAbstract-484">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-484" role="button" aria-expanded="false" aria-controls="collapseBibtext-484">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-484-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-484" role="button" aria-expanded="false" aria-controls="collapsePdf-484">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-484" id="collapsePdf-484">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/Pre-interpolation-loss-behaviour-venter_0-1.pdf" type="application/pdf">Pre-interpolation-loss-behaviour-venter_0.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-484" id="collapseAbstract-484">
        <div class="p-3 border-left-grey mt-2">
            <p>When training neural networks as classifiers, it is common to observe an increase in average test loss while still maintaining or improving the overall classification accuracy on the same dataset. In spite of the ubiquity of this phenomenon, it has not been well studied and is often dismissively attributed to an increase in borderline correct classifications. We present an empirical investigation that shows how this phenomenon is actually a result of the differential manner by which test samples are processed. In essence: test loss does not increase overall, but only for a small minority of samples. Large representational capacities allow losses to decrease for the vast majority of test samples at the cost of extreme increases for others. This effect seems to be mainly caused by increased parameter values relating to the correctly processed sample features. Our findings contribute to the practical understanding of a common behaviour of deep neural networks. We also discuss the implications of this work for network optimisation and generalisation.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-484" id="collapseBibtext-484">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;484,
&nbsp;&nbsp;author = &#123;Arthur Venter and Marthinus Theunissen and Marelie Davel&#125;,
&nbsp;&nbsp;title = &#123;Pre-interpolation loss behaviour in neural networks&#125;,
&nbsp;&nbsp;abstract = &#123;When training neural networks as classifiers, it is common to observe an increase in average test loss while still maintaining or improving the overall classification accuracy on the same dataset. In spite of the ubiquity of this phenomenon, it has not been well studied and is often dismissively attributed to an increase in borderline correct classifications. We present an empirical investigation that shows how this phenomenon is actually a result of the differential manner by which test samples are processed. In essence: test loss does not increase overall, but only for a small minority of samples. Large representational capacities allow losses to decrease for the vast majority of test samples at the cost of extreme increases for others. This effect seems to be mainly caused by increased parameter values relating to the correctly processed sample features. Our findings contribute to the practical understanding of a common behaviour of deep neural networks. We also discuss the implications of this work for network optimisation and generalisation.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Communications in Computer and Information Science&#125;,
&nbsp;&nbsp;volume = &#123;1342&#125;,
&nbsp;&nbsp;pages = &#123;296-309&#125;,
&nbsp;&nbsp;publisher = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-3-030-66151-9&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1007/978-3-030-66151-9_19&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-485">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Myburgh JC, Mouton C, Davel MH. Tracking translation invariance in CNNs. <i>Communications in Computer and Information Science</i>. 2020;1342. doi:https://doi.org/10.1007/978-3-030-66151-9_18.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-485" role="button" aria-expanded="false" aria-controls="collapseAbstract-485">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-485" role="button" aria-expanded="false" aria-controls="collapseBibtext-485">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-485-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-485" role="button" aria-expanded="false" aria-controls="collapsePdf-485">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-485" id="collapsePdf-485">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/TrackingTranslationInvariance_Myburgh-1.pdf" type="application/pdf">TrackingTranslationInvariance_Myburgh.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-485" id="collapseAbstract-485">
        <div class="p-3 border-left-grey mt-2">
            <p>Although Convolutional Neural Networks (CNNs) are widely used, their translation invariance (ability to deal with translated inputs) is still subject to some controversy. We explore this question using translation-sensitivity maps to quantify how sensitive a standard CNN is to a translated input. We propose the use of cosine similarity as sensitivity metric over Euclidean distance, and discuss the importance of restricting the dimensionality of either of these metrics when comparing architectures. Our main focus is to investigate the effect of different architectural components of a standard CNN on that network’s sensitivity to translation. By varying convolutional kernel sizes and amounts of zero padding, we control the size of the feature maps produced, allowing us to quantify the extent to which these elements influence translation invariance. We also measure translation invariance at different locations within the CNN to determine the extent to which convolutional and fully connected layers, respectively, contribute to the translation invariance of a CNN as a whole. Our analysis indicates that both convolutional kernel size and feature map size have a systematic influence on translation invariance. We also see that convolutional layers contribute less than expected to translation invariance, when not specifically forced to do so.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-485" id="collapseBibtext-485">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;485,
&nbsp;&nbsp;author = &#123;Johannes Myburgh and Coenraad Mouton and Marelie Davel&#125;,
&nbsp;&nbsp;title = &#123;Tracking translation invariance in CNNs&#125;,
&nbsp;&nbsp;abstract = &#123;Although Convolutional Neural Networks (CNNs) are widely used, their translation invariance (ability to deal with translated inputs) is still subject to some controversy. We explore this question using translation-sensitivity maps to quantify how sensitive a standard CNN is to a translated input. We propose the use of cosine similarity as sensitivity metric over Euclidean distance, and discuss the importance of restricting the dimensionality of either of these metrics when comparing architectures. Our main focus is to investigate the effect of different architectural components of a standard CNN on that network’s sensitivity to translation. By varying convolutional kernel sizes and amounts of zero padding, we control the size of the feature maps produced, allowing us to quantify the extent to which these elements influence translation invariance. We also measure translation invariance at different locations within the CNN to determine the extent to which convolutional and fully connected layers, respectively, contribute to the translation invariance of a CNN as a whole. Our analysis indicates that both convolutional kernel size and feature map size have a systematic influence on translation invariance. We also see that convolutional layers contribute less than expected to translation invariance, when not specifically forced to do so.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Communications in Computer and Information Science&#125;,
&nbsp;&nbsp;volume = &#123;1342&#125;,
&nbsp;&nbsp;pages = &#123;282-295&#125;,
&nbsp;&nbsp;publisher = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;isbn = &#123;978-3-030-66151-9&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1007/978-3-030-66151-9_18&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-486">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Mouton C, Myburgh JC, Davel MH. Stride and translation invariance in CNNs. <i>Communications in Computer and Information Science </i>. 2020;1342. doi:https://doi.org/10.1007/978-3-030-66151-9_17.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-486" role="button" aria-expanded="false" aria-controls="collapseAbstract-486">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-486" role="button" aria-expanded="false" aria-controls="collapseBibtext-486">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-486-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-486" role="button" aria-expanded="false" aria-controls="collapsePdf-486">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-486" id="collapsePdf-486">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/SlideAndTranslationInvariance_Mouton-1.pdf" type="application/pdf">SlideAndTranslationInvariance_Mouton.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-486" id="collapseAbstract-486">
        <div class="p-3 border-left-grey mt-2">
            <p>Convolutional Neural Networks have become the standard for image classification tasks, however, these architectures are not invariant to translations of the input image. This lack of invariance is attributed to the use of stride which subsamples the input, resulting in a loss of information, and fully connected layers which lack spatial reasoning. We show that stride can greatly benefit translation invariance given that it is combined with sufficient similarity between neighbouring pixels, a characteristic which we refer to as local homogeneity. We also observe that this characteristic is dataset-specific and dictates the relationship between pooling kernel size and stride required for translation invariance. Furthermore we find that a trade-off exists between generalization and translation invariance in the case of pooling kernel size, as larger kernel sizes lead to better invariance but poorer generalization. Finally we explore the efficacy of other solutions proposed, namely global average pooling, anti-aliasing, and data augmentation, both empirically and through the lens of local homogeneity.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-486" id="collapseBibtext-486">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;486,
&nbsp;&nbsp;author = &#123;Coenraad Mouton and Johannes Myburgh and Marelie Davel&#125;,
&nbsp;&nbsp;title = &#123;Stride and translation invariance in CNNs&#125;,
&nbsp;&nbsp;abstract = &#123;Convolutional Neural Networks have become the standard for image classification tasks, however, these architectures are not invariant to translations of the input image. This lack of invariance is attributed to the use of stride which subsamples the input, resulting in a loss of information, and fully connected layers which lack spatial reasoning. We show that stride can greatly benefit translation invariance given that it is combined with sufficient similarity between neighbouring pixels, a characteristic which we refer to as local homogeneity. We also observe that this characteristic is dataset-specific and dictates the relationship between pooling kernel size and stride required for translation invariance. Furthermore we find that a trade-off exists between generalization and translation invariance in the case of pooling kernel size, as larger kernel sizes lead to better invariance but poorer generalization. Finally we explore the efficacy of other solutions proposed, namely global average pooling, anti-aliasing, and data augmentation, both empirically and through the lens of local homogeneity.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Communications in Computer and Information Science&#125;,
&nbsp;&nbsp;volume = &#123;1342&#125;,
&nbsp;&nbsp;pages = &#123;267-281&#125;,
&nbsp;&nbsp;publisher = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-3-030-66151-9&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.1007/978-3-030-66151-9_17&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">

<div class="mb-20" id="row-398">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Strydom RA, Barnard E. Classifying recognised speech with deep neural networks. In: <i>Southern African Conference for Artificial Intelligence Research</i>. South Africa: Southern African Conference for Artificial Intelligence Research; 2020.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-398" role="button" aria-expanded="false" aria-controls="collapseAbstract-398">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-398" role="button" aria-expanded="false" aria-controls="collapseBibtext-398">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-398-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-398" role="button" aria-expanded="false" aria-controls="collapsePdf-398">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-398" id="collapsePdf-398">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/Strydom-2020-recognising-classified-speech-1.pdf" type="application/pdf">Strydom-2020-recognising-classified-speech.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-398" id="collapseAbstract-398">
        <div class="p-3 border-left-grey mt-2">
            <p>We investigate whether word embeddings using deep neural networks can assist in the analysis of text produced by a speechrecognition system. In particular, we develop algorithms to identify which words are incorrectly detected by a speech-recognition system in broadcast news. The multilingual corpus used in this investigation contains speech from the eleven official South African languages, as well as Hindi. Popular word embedding algorithms such as Word2Vec and fastText are investigated and compared with context-specific embedding representations such as Doc2Vec and non-context specific statistical sentence embedding methods such as term frequency-inverse document frequency (TFIDF), which is used as our baseline method. These various embeddding methods are then used as fixed length input representations for a logistic regression and feed forward neural network classifier. The output is used as an additional categorical input feature to a CatBoost classifier to determine whether the words were correctly recognised. Other methods are also investigated, including a method that uses the word embedding itself and cosine similarity between specific keywords to identify whether a specific keyword was correctly detected. When relying only on the speech-text data, the best result was obtained using the TFIDF document embeddings as input features to a feed forward neural network. Adding the output from the feed forward neural network as an additional feature to the CatBoost classifier did not enhance the classifier’s performance compared to using the non-textual information provided, although adding the output from a weaker classifier was somewhat beneficial</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-398" id="collapseBibtext-398">
<div class="p-3 border-left-grey mt-2">
<pre>@&#123;398,
&nbsp;&nbsp;author = &#123;Rhyno Strydom and Etienne Barnard&#125;,
&nbsp;&nbsp;title = &#123;Classifying recognised speech with deep neural networks&#125;,
&nbsp;&nbsp;abstract = &#123;We investigate whether word embeddings using deep neural networks can assist in the analysis of text produced by a speechrecognition system. In particular, we develop algorithms to identify which words are incorrectly detected by a speech-recognition system in broadcast news. The multilingual corpus used in this investigation contains speech from the eleven official South African languages, as well as Hindi. Popular word embedding algorithms such as Word2Vec and fastText are investigated and compared with context-specific embedding representations such as Doc2Vec and non-context specific statistical sentence embedding methods such as term frequency-inverse document frequency (TFIDF), which is used as our baseline method. These various embeddding methods are then used as fixed length input representations for a logistic regression and feed forward neural network classifier. The output is used as an additional categorical input feature to a CatBoost classifier to determine whether the words were correctly recognised. Other methods are also investigated, including a method that uses the word embedding itself and cosine similarity between specific keywords to identify whether a specific keyword was correctly detected. When relying only on the speech-text data, the best result was obtained using the TFIDF document embeddings as input features to a feed forward neural network. Adding the output from the feed forward neural network as an additional feature to the CatBoost classifier did not enhance the classifier’s performance compared to using the non-textual information provided, although adding the output from a weaker classifier was somewhat beneficial&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;pages = &#123;191-205&#125;,
&nbsp;&nbsp;month = &#123;22/02/2021 - 26/02/2021&#125;,
&nbsp;&nbsp;publisher = &#123;Southern African Conference for Artificial Intelligence Research&#125;,
&nbsp;&nbsp;address = &#123;South Africa&#125;,
&nbsp;&nbsp;isbn = &#123;978-0-620-89373-2&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
    <div class="w-100 views-row">
    
<div class="mb-20" id="row-394">
    <div class="bibcite-citation">
      <div class="csl-bib-body">
  <div class="csl-entry"><div class="csl-left-margin">1.</div><div class="csl-right-inline">Theunissen MW, Davel MH, Barnard E. Benign interpolation of noise in deep learning. <i>South African Computer Journal</i>. 2020;32(2). doi:https://doi.org/10.18489/sacj.v32i2.833.</div></div>
</div>
  </div>

    
    <div class="w-100 mt-2">
        <a class="abstract mr-2" data-toggle="collapse" href="#collapseAbstract-394" role="button" aria-expanded="false" aria-controls="collapseAbstract-394">
           <i class="fas fa-angle-right icon-orange"></i> Abstract
        </a>
        <a class="bibtext mr-2" data-toggle="collapse" href="#collapseBibtext-394" role="button" aria-expanded="false" aria-controls="collapseBibtext-394">
           <i class="fas fa-angle-right icon-orange"></i> BibTex Entry
        </a>
        <a class="bibtext-export mr-2" href="../../bibcite/export/bibtex/bibcite_reference/bibcite_reference-394-BibTeX-1.bib"><i class="fas fa-angle-right icon-orange"></i> BibTeX Download
        </a>
                    <a class="pdf-files mr-2" data-toggle="collapse" href="#collapsePdf-394" role="button" aria-expanded="false" aria-controls="collapsePdf-394">
               <i class="fas fa-file-pdf icon-orange"></i> PDF
            </a>
                  
    </div>

    <div class="collapse" data-parent="#row-394" id="collapsePdf-394">
         <div class="p-3 border-left-grey mt-2 listing-files">
            
<span class="file file--mime-application-pdf file--application-pdf"> <a href="../../sites/default/files/2021-04/Benign-interpolation-theunissen-1.pdf" type="application/pdf">Benign-interpolation-theunissen.pdf</a></span>

            
            
        </div>
    </div>

    <div class="collapse" data-parent="#row-394" id="collapseAbstract-394">
        <div class="p-3 border-left-grey mt-2">
            <p>The understanding of generalisation in machine learning is in a state of flux, in part due to the ability of deep learning models to interpolate noisy training data and still perform appropriately on out-of-sample data, thereby contradicting long-held intuitions about the bias-variance trade off in learning. We expand upon relevant existing work by discussing local attributes of neural network training within the context of a relatively simple framework.We describe how various types of noise can be compensated for within the proposed framework in order to allow the deep learning model to generalise in spite of interpolating spurious function descriptors. Empirically,we support our postulates with experiments involving overparameterised multilayer perceptrons and controlled training data noise. The main insights are that deep learning models are optimised for training data modularly, with different regions in the function space dedicated to fitting distinct types of sample information. Additionally,we show that models tend to fit uncorrupted samples first. Based on this finding, we propose a conjecture to explain an observed instance of the epoch-wise double-descent phenomenon. Our findings suggest that the notion of model capacity needs to be modified to consider the distributed way training data is fitted across sub-units.</p>
        </div>
    </div>

    <div class="collapse" data-parent="#row-394" id="collapseBibtext-394">
<div class="p-3 border-left-grey mt-2">
<pre>@article&#123;394,
&nbsp;&nbsp;author = &#123;Marthinus Theunissen and Marelie Davel and Etienne Barnard&#125;,
&nbsp;&nbsp;title = &#123;Benign interpolation of noise in deep learning&#125;,
&nbsp;&nbsp;abstract = &#123;The understanding of generalisation in machine learning is in a state of flux, in part due to the ability of deep learning models to interpolate noisy training data and still perform appropriately on out-of-sample data, thereby contradicting long-held intuitions about the bias-variance trade off in learning. We expand upon relevant existing work by discussing local attributes of neural network training within the context of a relatively simple framework.We describe how various types of noise can be compensated for within the proposed framework in order to allow the deep learning model to generalise in spite of interpolating spurious function descriptors. Empirically,we support our postulates with experiments involving overparameterised multilayer perceptrons and controlled training data noise. The main insights are that deep learning models are optimised for training data modularly, with different regions in the function space dedicated to fitting distinct types of sample information. Additionally,we show that models tend to fit uncorrupted samples first. Based on this finding, we propose a conjecture to explain an observed instance of the epoch-wise double-descent phenomenon. Our findings suggest that the notion of model capacity needs to be modified to consider the distributed way training data is fitted across sub-units.&#125;,
&nbsp;&nbsp;year = &#123;2020&#125;,
&nbsp;&nbsp;journal = &#123;South African Computer Journal&#125;,
&nbsp;&nbsp;volume = &#123;32&#125;,
&nbsp;&nbsp;pages = &#123;80-101&#125;,
&nbsp;&nbsp;issue = &#123;2&#125;,
&nbsp;&nbsp;publisher = &#123;South African Institute of Computer Scientists and Information Technologists&#125;,
&nbsp;&nbsp;isbn = &#123;ISSN: 1015-7999; E:2313-7835&#125;,
&nbsp;&nbsp;doi = &#123;https://doi.org/10.18489/sacj.v32i2.833&#125;,
&#125;
</pre>
</div>
</div>
</div></div>
</div>

      <nav aria-label="pagination-heading">
    <h4 id="pagination-heading" class="sr-only">Pagination</h4>
    <ul class="pagination js-pager__items">
                                                        <li class="page-item active">
                      <span class="page-link">1</span>
                  </li>
              <li class="page-item ">
                      <a href="research-publications-5.html?page=1" title="" class="page-link">2</a>
                  </li>
              <li class="page-item ">
                      <a href="research-publications-6.html?page=2" title="" class="page-link">3</a>
                  </li>
                                      <li class="pager__item--next">
          <a href="research-publications-5.html?page=1" title="Go to next page" rel="next" class="page-link">
            <span aria-hidden="true">››</span>
            <span class="sr-only">Next page</span>
          </a>
        </li>
                          <li class="page-item">
          <a href="research-publications-6.html?page=2" title="Go to last page" class="page-link">
            <span aria-hidden="true">Last »</span>
            <span class="sr-only">Last page</span>
          </a>
        </li>
          </ul>
  </nav>


  
  

  
  
</div>
</div>

    </div>
  </div>


                </section>
              </main>
                          <div class="sidebar col-md-4 col-lg-3 order-first" id="sidebar_first">
                <aside class="section" role="complementary">
                    <div class="views-element-container card card-bordered shadow mb-4 block-views block-views-blockgroup-owners-block-2" id="block-views-block-group-owners-block-2">
  
      <h4 class="p-3 mt-2 mb-0 text-blue">Group Co-ordinator</h4>
    
      <div class="content p-3">
      <div class="col-auto"><div class="view view-group-owners view-id-group_owners view-display-id-block_2 js-view-dom-id-4c81f0ee9a0116fedd54c1d1b22daa26c8822ffd48344df6036c4dd9d2edcba8">
  
    
      
      <div class="view-content row">
          <div class="views-row">
    <div class="media">
  <div class="mr-2 thumb-rounded thumb-xs">  <a href="../../user/54-4.html"><img src="../../sites/default/files/styles/profile/public/pictures/2019-11/Marelie%20Davel-1.jpg?h=43ea6a7e&amp;itok=IN9OYLrJ" width="100" height="100" alt="" loading="lazy" typeof="foaf:Image" class="image-style-profile">

</a>
</div>
  <div class="media-body">
    <h6 class="mb-2">Marelie Davel</h6>
   	<p class="text-small m-0">Researcher</p>
	<p class="text-small m-0">North-West University</p>
	<p class="text-small mb-3"></p>
	<a class="btn btn-blue-outline btn-sml mb-3" href="../../user/54-4.html">View profile</a>
  </div>
</div>

  </div>

    </div>
  
          </div>
</div>

    </div>
  </div>


                </aside>
              </div>
                                  </div>
        </div>
          </div>
          <div class="d-flex w-100">
        <section class="region region-brands">
    <div id="block-companylogos" class="block block-block-content block-block-content4f032544-7aeb-42fc-a5c4-5689cc32dcac">
  
    
      <div class="content">
      
            <div class="clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item"><ul><li><a href="https://www.csir.co.za" target="_blank"><img alt="CSIR" data-entity-type="file" data-entity-uuid="3488e975-cefd-43d0-833f-c7c966044a41" src="../../sites/default/files/inline-images/csir_logo_wide-1.png" width="592" height="180" loading="lazy"></a></li>
	<li><a href="https://www.dst.gov.za" target="_blank"><img alt="DSI" data-entity-type="file" data-entity-uuid="8297cef2-3f93-42ac-9f41-306426e612ba" src="../../sites/default/files/inline-images/dsi_logo-1.png" width="853" height="260" loading="lazy"></a></li>
	<li><a href="https://sacoronavirus.co.za" target="_blank"><img alt="Covid-19" data-entity-type="file" data-entity-uuid="fb53689c-66c1-4b22-a659-3da75ebc644b" src="../../sites/default/files/inline-images/covid-footer_0-1.png" class="align-right" width="900" height="260" loading="lazy"></a></li>
</ul></div>
      
    </div>
  </div>

  </section>

    </div>
     <footer class="site-footer pt-5 pb-6">
              <div class="container">
                      <div class="site-footer__top clearfix">
                <section class="row region region-footer-first">
    <nav role="navigation" aria-labelledby="block-cair-sass-footer-menu" id="block-cair-sass-footer" class="block block-menu navigation menu--footer">
            
  <h2 class="sr-only" id="block-cair-sass-footer-menu">Footer menu</h2>
  

        
              <ul block="block-cair-sass-footer" class="clearfix nav navbar-nav">
                    <li class="nav-item">
                <a href="../../events-1.html" class="nav-link nav-link--events" data-drupal-link-system-path="node/255">Events</a>
              </li>
                <li class="nav-item">
                <a href="../../news-1.html" class="nav-link nav-link--news" data-drupal-link-system-path="node/254">News</a>
              </li>
                <li class="nav-item">
                <a href="../../about-1.html" class="nav-link nav-link--about" data-drupal-link-system-path="node/4">About</a>
              </li>
                <li class="nav-item">
                <a href="../../contact-1.html" class="nav-link nav-link--contact" data-drupal-link-system-path="webform/contact">Contact</a>
              </li>
        </ul>
  


  </nav>
<nav role="navigation" aria-labelledby="block-cair-sass-account-menu-menu" id="block-cair-sass-account-menu" class="block block-menu navigation menu--account">
            
  <h2 class="sr-only" id="block-cair-sass-account-menu-menu">User account menu</h2>
  

        
              <div block="block-cair-sass-account-menu" class="clearfix nav">
                      <a href="../../user/login-1.html" class="nav-link nav-link--user-login" data-drupal-link-system-path="user/login">Log in</a>
            </div>
      


  </nav>

  </section>

            </div>
                            </div>
          </footer>
  </div>
</div>

  </div>

    
    <script type="application/json" data-drupal-selector="drupal-settings-json">{"path":{"baseUrl":"\/","scriptPath":null,"pathPrefix":"","currentPath":"group\/4\/research-publications","currentPathIsAdmin":false,"isFront":false,"currentLanguage":"en"},"pluralDelimiter":"\u0003","suppressDeprecationErrors":true,"ajaxTrustedUrl":{"\/search":true},"user":{"uid":0,"permissionsHash":"0894c071b06b3d56de3346155916aa642009fcc0d2ed55dbcc6226fa6ed06924"}}</script>
<script src="../../core/assets/vendor/jquery/jquery.min-1.js?v=3.6.3"></script>
<script src="../../core/misc/polyfills/element.matches-1.js?v=9.5.8"></script>
<script src="../../core/misc/polyfills/object.assign-1.js?v=9.5.8"></script>
<script src="../../core/assets/vendor/once/once.min-1.js?v=1.0.1"></script>
<script src="../../core/assets/vendor/jquery-once/jquery.once.min-1.js?v=2.2.3"></script>
<script src="../../core/misc/drupalSettingsLoader-1.js?v=9.5.8"></script>
<script src="../../core/misc/drupal-1.js?v=9.5.8"></script>
<script src="../../core/misc/drupal.init-1.js?v=9.5.8"></script>
<script src="../../menu/page.js" async=""></script>
<script src="../../modules/contrib/addtoany/js/addtoany-1.js?v=9.5.8"></script>
<script src="../../core/misc/jquery.once.bc-1.js?v=9.5.8"></script>
<script src="../../themes/custom/cair_sass/js/popper.min-1.js?v=9.5.8"></script>
<script src="../../themes/custom/cair_sass/js/bootstrap.min-1.js?v=9.5.8"></script>
<script src="../../themes/custom/cair_sass/js/jquery.matchHeight-min-1.js?v=9.5.8"></script>
<script src="../../themes/custom/cair_sass/js/theme-1.js?v=9.5.8"></script>
<script src="../../themes/custom/cair_sass/js/global-1.js?v=9.5.8"></script>
<script src="../../libraries/particles.js/particles-1.js?v=2.0.0"></script>
<script src="../../modules/custom/particlesjs/particlesjs_cair/js/particlesjs_cair-1.js?v=1.x"></script>

  </body>
</html>
